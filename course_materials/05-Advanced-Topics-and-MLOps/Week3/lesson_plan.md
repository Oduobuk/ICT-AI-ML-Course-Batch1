
# Month 5, Week 3: Explainable and Responsible AI (XAI)

## Lesson Plan

*   **Addressing Bias in Data and Models:**
    *   **Concept:** Understand the different types of bias that can occur in machine learning models and how to mitigate them.

*   **Interpretability vs. Explainability:**
    *   **Concept:** Differentiate between interpretability and explainability and understand the importance of both.

*   **Techniques like LIME and SHAP:**
    *   **Concept:** Learn about LIME (Local Interpretable Model-agnostic Explanations) and SHAP (SHapley Additive exPlanations), two popular techniques for explaining the predictions of machine learning models.
    *   **Hands-on:** Use LIME and SHAP to explain the predictions of a machine learning model.

## Reading Assignments

*   **Primary Reading:**
    *   **"Interpretable Machine Learning" by Christoph Molnar:**
        *   Chapter 1: Introduction.
        *   Chapter 5: Local Interpretable Model-agnostic Explanations (LIME).
        *   Chapter 6: Shapley Additive Explanations (SHAP).

*   **Further Reading:**
    *   **"The Ethical Algorithm" by Michael Kearns and Aaron Roth.**

## Assignments

*   **Assignment 1: Auditing a Model for Bias**
    *   Choose a machine learning model that you have built in a previous assignment.
    *   Audit the model for bias and identify any potential sources of bias.
    *   Propose a strategy for mitigating the bias in the model.

*   **Assignment 2: Explaining a Model with LIME**
    *   Use the model from Assignment 1.
    *   Use LIME to explain the predictions of the model.
    *   Interpret the explanations and discuss the insights that you have gained.

*   **Assignment 3: Explaining a Model with SHAP**
    *   Use the model from Assignment 1.
    *   Use SHAP to explain the predictions of the model.
    *   Compare the explanations from SHAP with the explanations from LIME.
