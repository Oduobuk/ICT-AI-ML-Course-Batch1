
# Month 5, Week 1: Reinforcement Learning (Introduction)

## Lesson Plan

*   **Markov Decision Processes (MDPs):**
    *   **Concept:** Understand the mathematical framework for modeling decision-making in situations where outcomes are partly random and partly under the control of a decision-maker.
    *   **Hands-on:** Formulate a simple problem (e.g., a grid world) as an MDP.

*   **Q-learning and Value Functions:**
    *   **Concept:** Learn about Q-learning, a model-free reinforcement learning algorithm that learns a policy that tells an agent what action to take under what circumstances.
    *   **Hands-on:** Implement a simple Q-learning algorithm to solve a grid world problem.

*   **Policy Gradients:**
    *   **Concept:** Understand the basic idea of policy gradients, a class of reinforcement learning algorithms that learn a policy directly, without learning a value function.

## Reading Assignments

*   **Primary Reading:**
    *   **"Reinforcement Learning: An Introduction, 2nd Edition" by Sutton and Barto:**
        *   Chapter 3: Finite Markov Decision Processes.
        *   Chapter 6: Temporal-Difference Learning (focus on Q-learning).

*   **Further Reading:**
    *   **Spinning Up in Deep RL by OpenAI:** [https://spinningup.openai.com/en/latest/](https://spinningup.openai.com/en/latest/)

## Assignments

*   **Assignment 1: Markov Decision Processes**
    *   Formulate a real-world problem as an MDP. Identify the states, actions, transition probabilities, and rewards.

*   **Assignment 2: Q-learning**
    *   Implement a Q-learning algorithm to solve a simple grid world problem.
    *   Experiment with different learning rates and discount factors.

*   **Assignment 3: Policy Gradients**
    *   Read the chapter on policy gradients in "Reinforcement Learning: An Introduction" and write a short summary of the key ideas.
